{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_alignment\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "#fa = face_alignment.FaceAlignment(face_alignment.LandmarksType.TWO_D, flip_input=False, device='cpu')\n",
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType.TWO_D, device='cpu', face_detector='blazeface')\n",
    "\n",
    "\n",
    "face_landmarks = {\n",
    "    'Jaw': {'range': (0, 17), 'color': (0, 255, 255)},        # Cyan for Jaw\n",
    "    'Eyebrows': {'range': (17, 27), 'color': (255, 255, 0)},  # Yellow for Eyebrows\n",
    "    'Nose': {'range': (27, 36), 'color': (255, 0, 0)},        # Blue for Nose\n",
    "    'Eyes': {'range': (36, 48), 'color': (0, 0, 255)},        # Red for Eyes\n",
    "    'Outer Lips': {'range': (48, 60), 'color': (255, 0, 255)},# Magenta for Outer Lips\n",
    "    'Inner Lips': {'range': (60, 68), 'color': (128, 0, 128)} # Purple for Inner Lips\n",
    "}\n",
    "\n",
    "eye_threshold = 5\n",
    "jaw_threshold = 5\n",
    "mouth_threshold = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('data/raw/a_numbers.mp4')\n",
    "frames = []\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    #frame = cv2.resize(frame, None, fx=0.2, fy=0.2, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VideoWriter parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "fps = 32  # Change the frames per second as needed\n",
    "\n",
    "output_file = 'results/demo_trackers.mp4'\n",
    "frame_width, frame_height = frames[0].shape[1], frames[0].shape[0]\n",
    "\n",
    "# Create VideoWriter object\n",
    "out = cv2.VideoWriter(output_file, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "num_frames = len(frames)\n",
    "batch_size = 32\n",
    "frame_index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlazeFace: Execution time for batch 1-32: 8.04556131362915\n",
      "BlazeFace: Execution time for batch 33-64: 7.819885492324829\n",
      "BlazeFace: Execution time for batch 65-96: 7.685851335525513\n",
      "BlazeFace: Execution time for batch 97-128: 7.8086724281311035\n",
      "BlazeFace: Execution time for batch 129-160: 7.7580406665802\n",
      "BlazeFace: Execution time for batch 161-192: 7.957440137863159\n",
      "BlazeFace: Execution time for batch 193-224: 7.843115329742432\n",
      "BlazeFace: Execution time for batch 225-256: 7.826949119567871\n",
      "BlazeFace: Execution time for batch 257-288: 7.891754627227783\n",
      "BlazeFace: Execution time for batch 289-315: 6.678290367126465\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, num_frames, batch_size):\n",
    "    batch_frames = frames[i:i+batch_size]\n",
    "    \n",
    "    # Convert frames to the required format (assuming frames are in BGR format)\n",
    "    batch = np.stack(batch_frames)\n",
    "    batch = torch.Tensor(batch.transpose(0, 3, 1, 2))\n",
    "    \n",
    "    t_start = time.time()\n",
    "    preds = fa.get_landmarks_from_batch(batch)\n",
    "    print(f'BlazeFace: Execution time for batch {i+1}-{min(i+batch_size, num_frames)}: {time.time() - t_start}')\n",
    "    \n",
    "    # Visualize results and write to video\n",
    "    for j, pred in enumerate(preds):\n",
    "\n",
    "        frame_index = i + j\n",
    "        if frame_index < num_frames:\n",
    "            frame = frames[frame_index]        \n",
    "\n",
    "            x_values = pred[:, 0].astype(np.int64)\n",
    "            y_values = pred[:, 1].astype(np.int64)\n",
    "\n",
    "            # Plot all points using scatter plot with specific colors for facial parts\n",
    "            for part, part_info in face_landmarks.items():\n",
    "                start, end = part_info['range']\n",
    "                color = part_info['color']\n",
    "    \n",
    "                # Draw circles for each facial part with different colors\n",
    "                for k in range(start, end):\n",
    "                    cv2.circle(frame, (int(x_values[k]), int(y_values[k])), 10, color, -1)\n",
    "\n",
    "            \n",
    "            # Write the frame with landmarks to the video\n",
    "            out.write(frame)\n",
    "\n",
    "# Release the VideoWriter and close the output file\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
